import requests
import utils.tool as tool
import pytz, time,json
from datetime import datetime
import urllib
from selenium import webdriver
from dateutil import parser

TRACKER_URL = "https://security-tracker.debian.org/tracker/%s"



def fetch_cve_info(cve_id):
    turl = TRACKER_URL % cve_id
    print(turl)

    cnt_retry = 3
    while(cnt_retry>0):
        try:
            r = requests.get(turl, timeout = 60)
            break
        except:
            cnt_retry-=1
            # print(r.status_code)
            time.sleep(0.5)
            continue

    content = r.text[r.text.index('<header><h1>'+cve_id+'</h1></header>'):]
    ob_cve_arr = []
    
    severity = ""
    if '<b>NVD severity</b>' in content:
        temp = content[content.index('<b>NVD severity</b>'):]
        temp = temp[temp.index('<td>'):]
        temp = temp[:temp.index('</td>')]
        severity = tool.remove_html_tags(temp)

    desc = ""
    if '<b>Description</b>' in content:
        temp = content[content.index('<b>Description</b>'):]
        temp = temp[temp.index('<td'):]
        temp = temp[:temp.index('</td>')]
        desc = tool.remove_html_tags(temp)
    
    refs = ""
    if '<b>References</b>' in content:
        temp = content[content.index('<b>References</b>'):]
        temp = temp[temp.index('<td'):]
        temp = temp[:temp.index('</td>')]
        refs = tool.remove_html_tags(temp)

    ids = ""
    if '<b>Debian Bugs</b>' in content:
        temp = content[content.index('<b>Debian Bugs</b>'):]
        temp = temp[temp.index('<a'):]
        temp = temp[:temp.index('</td>')]
        ids = tool.remove_html_tags(temp)
    
    temp = ids.split(',')
    for ss in temp:
        if ss.strip() == "":
            continue
        ob_cve = {}
        ob_cve['severity'] = severity
        ob_cve['dist_id'] = ss.strip()
        ob_cve['description'] = desc.strip()
        ob_cve['references'] = refs.strip()
        
        ob_cve_arr.append(ob_cve)
    

    return ob_cve_arr

def fetch_security_advisory_list():
    advisories = []

    url = "https://www.debian.org/security/crossreferences"
    r = requests.get(url, timeout = 60)
    content = r.text[r.text.index('<div id="content">'):]
    content = content[:content.index('<div id="footer">')].lower()
    cnt_dsa = content.count('<tr valign="top">')
    # print(cnt_dsa)
    content = content[content.index('<tr valign="top">'):]
    
    for i in range(0, cnt_dsa):
        tmp = content[content.index('<tr valign="top">'):]
        tmp = tmp[:tmp.index('</tr>')]

        tb_cells = tmp.split("<td>")
        cve_ids = []
        if len(tb_cells)>1:
            # print(len(tb_cells))
            dsa_url = tb_cells[1]
            dsa_url = dsa_url[dsa_url.index('href="')+6:]
            dsa_url = dsa_url[:dsa_url.index('"')]
            dsa_id = tool.remove_html_tags(tb_cells[1]).upper()

            cve_ids = tool.remove_html_tags(tb_cells[2]).upper().split(',')
            cve_ids = list(filter(None, cve_ids))
            # print(dsa_url, dsa_id, cve_ids)

            if dsa_id.startswith("DSA-"):
                for cve in cve_ids:
                    ob= {}
                    ob["cve_id"] = cve.strip()
                    ob["dsa_id"] = dsa_id.strip()
                    ob["dsa_url"] = dsa_url.strip()
                    advisories.append(ob)
        if i < cnt_dsa -1:
            content = content[content.index('<tr valign="top">', 10):]
        
    return advisories

def fetch_advisory(dsa_url):
    # print(dsa_url)
    r = requests.get(dsa_url, timeout = 60)
    content = r.text[r.text.index('<div id="content">'):]
    content = content[:content.index('<div id="footer">')].lower()

    ob = {}
    tmp = content[content.index('<dt>date reported:</dt>'):]
    tmp = tmp[tmp.index('<dd>'):tmp.index('</dd>')]
    ob['publish_date'] = parser.parse(tool.remove_html_tags(tmp))

    tmp = content[content.index('<dt>affected packages:</dt>'):]
    tmp = tmp[tmp.index('<dd>'):tmp.index('</dd>')]
    ob['affected_pkg'] = tool.remove_html_tags(tmp).strip()

    tmp = content[content.index('<dt>vulnerable:</dt>'):]
    tmp = tmp[tmp.index('<dd'):tmp.index('</dd>')]
    ob['vulnerable'] = True if tool.remove_html_tags(tmp).strip() == "yes" else False 
    
    # print(ob)
    return ob